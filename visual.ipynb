{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('env')",
   "metadata": {
    "interpreter": {
     "hash": "9d223f7fc3d0df1582a6cc73651822e12e2337e084fe9a5be51861a0660f43c8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "from itertools import combinations\n",
    "import copy\n",
    "import backbone as backbone\n",
    "import configs\n",
    "from data.datamgr import SimpleDataManager, SetDataManager\n",
    "from methods.baselinetrain import BaselineTrain\n",
    "from methods.gnnnet import GnnNet\n",
    "from methods.baselinefinetune import BaselineFinetune\n",
    "from methods.protonet import ProtoNet\n",
    "from methods import damsl_v1\n",
    "from methods import damsl_v1_proto\n",
    "from methods import damsl_v2\n",
    "from methods import damsl_v2_gnn\n",
    "from methods import damsl_v2_proto\n",
    "from methods.protonet import euclidean_dist\n",
    "\n",
    "configs.save_dir = 'logs_final_train' ##override\n",
    "from io_utils import model_dict, parse_args, get_resume_file, get_best_file, get_assigned_file \n",
    "\n",
    "from utils import *\n",
    "\n",
    "from datasets import ISIC_few_shot, EuroSAT_few_shot, CropDisease_few_shot, Chest_few_shot, miniImageNet_few_shot, DTD_few_shot, CUB_few_shot, cifar_few_shot, caltech256_few_shot, cars_few_shot, plantae_few_shot, places_few_shot\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, dim, n_way):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Linear(dim, n_way)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def finetune_classify(liz_x,y, model, state_in, save_it, linear = False, flatten = True, n_query = 15, ds= False, pretrained_dataset='miniImageNet', freeze_backbone = False, n_way = 5, n_support = 5): \n",
    "    ###############################################################################################\n",
    "    # load pretrained model on miniImageNet\n",
    "    if \"damsl_v1\" in params.method or params.method == \"gnnnet\":\n",
    "      pretrained_model = model_dict[params.model](flatten = flatten)\n",
    "      state_temp = copy.deepcopy(state_in)\n",
    "      state_keys = list(state_temp.keys())\n",
    "      for _, key in enumerate(state_keys):\n",
    "          if \"feature.\" in key:\n",
    "              newkey = key.replace(\"feature.\",\"\")  # an architecture model has attribute 'feature', load architecture feature to backbone by casting name from 'feature.trunk.xx' to 'trunk.xx'  \n",
    "              state_temp[newkey] = state_temp.pop(key)\n",
    "          else:\n",
    "              state_temp.pop(key)\n",
    "      pretrained_model.load_state_dict(state_temp)\n",
    "    else:\n",
    "      pretrained_model = copy.deepcopy(model.feature_baseline2)\n",
    "    \n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    ###############################################################################################\n",
    "\n",
    "    classifier = Classifier(model.feature_baseline.final_feat_dim, model.n_way)\n",
    "\n",
    "    ###############################################################################################\n",
    "    \n",
    "    x = liz_x[0] ### non-changed one\n",
    "    #print(x.shape)\n",
    "    #print(n_query)\n",
    "    model.n_query = n_query\n",
    "    #x = x\n",
    "    x_var = Variable(x)\n",
    "    \n",
    "    support_size = n_way * n_support \n",
    "    batch_size = 8\n",
    "\n",
    "    y_a_i = Variable( torch.from_numpy( np.repeat(range( n_way ), n_support ) )).to(device) # (25,)\n",
    "\n",
    "    x_b_i = x_var[:, n_support:,:,:,:].contiguous().view( n_way* n_query,   *x.size()[2:]).to(device)\n",
    "    x_a_i = x_var[:,:n_support,:,:,:].contiguous().view( n_way* n_support, *x.size()[2:]) # (25, 3, 224, 224)\n",
    "    x_a_i_original = copy.deepcopy(x_a_i.to(device))\n",
    "    x_inn = x_var.view(n_way* (n_support + n_query), *x.size()[2:]).to(device)\n",
    "    \n",
    "    ### to load all the changed examples\n",
    "\n",
    "    x_a_i = torch.cat((x_a_i, x_a_i), dim = 0) ##oversample the first one\n",
    "    y_a_i = torch.cat((y_a_i, y_a_i), dim = 0)\n",
    "    for x_aug in liz_x[1:]:\n",
    "      #x_aug = x_aug\n",
    "      x_aug = Variable(x_aug)\n",
    "      x_a_aug = x_aug[:,:n_support,:,:,:].contiguous().view( n_way* n_support, *x.size()[2:])\n",
    "      y_a_aug = Variable( torch.from_numpy( np.repeat(range( n_way ), n_support ) )).to(device)\n",
    "      x_a_i = torch.cat((x_a_i, x_a_aug), dim = 0)\n",
    "      y_a_i = torch.cat((y_a_i, y_a_aug.to(device)), dim = 0)\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    #optimizer = torch.optim.Adam(model.parameters())\n",
    "    names = []\n",
    "    for name, param in pretrained_model.named_parameters():\n",
    "      if param.requires_grad:\n",
    "        #print(name)\n",
    "        names.append(name)\n",
    "    \n",
    "    names_sub = names[:-9] ### last Resnet block can adapt\n",
    "\n",
    "    for name, param in pretrained_model.named_parameters():\n",
    "      if name in names_sub:\n",
    "        param.requires_grad = False\n",
    "\n",
    "    if freeze_backbone is False:\n",
    "        delta_opt = torch.optim.Adam(filter(lambda p: p.requires_grad, pretrained_model.parameters()), lr = 0.01)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss().to(device) ##change this code up ## dorop n way\n",
    "    classifier_opt = torch.optim.Adam(classifier.parameters(), lr = 0.01) ##try it with weight_decay\n",
    "    pretrained_model.to(device)\n",
    "    classifier.to(device)\n",
    "    ###############################################################################################\n",
    "    total_epoch = params.fine_tune_epoch\n",
    "\n",
    "    if freeze_backbone is False:\n",
    "        pretrained_model.train()\n",
    "    \n",
    "    #pretrained_model_fixed = copy.deepcopy(pretrained_model)\n",
    "    #pretrained_model_fixed.eval()\n",
    "    classifier.train()\n",
    "    lengt = len(liz_x) +1\n",
    "    for epoch in range(total_epoch):\n",
    "        rand_id = np.random.permutation(support_size * lengt)\n",
    "\n",
    "        for j in range(0, support_size * lengt, batch_size):\n",
    "            classifier_opt.zero_grad()\n",
    "            if freeze_backbone is False:\n",
    "                delta_opt.zero_grad()\n",
    "\n",
    "            #####################################\n",
    "            selected_id = torch.from_numpy( rand_id[j: min(j+batch_size, support_size * lengt)]).to(device)\n",
    "            \n",
    "            z_batch = x_a_i[selected_id].to(device)\n",
    "            y_batch = y_a_i[selected_id] \n",
    "            #####################################\n",
    "\n",
    "            output = pretrained_model(z_batch)\n",
    "            if flatten == False:\n",
    "              avgpool = nn.AvgPool2d(7)\n",
    "              flat = backbone.Flatten()\n",
    "              output = flat(avgpool(output))\n",
    "            scores  = classifier(output)\n",
    "            loss = loss_fn(scores, y_batch)\n",
    "\n",
    "            #####################################\n",
    "            loss.backward()\n",
    "\n",
    "            classifier_opt.step()\n",
    "            \n",
    "            if freeze_backbone is False:\n",
    "                delta_opt.step()\n",
    "\n",
    "    \n",
    "    #output_support = pretrained_model(x_a_i_original.to(device)).view(n_way, n_support, -1)\n",
    "    #output_query = pretrained_model(x_b_i.to(device)).view(n_way,n_support+n_query,-1)\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "    output_all = pretrained_model(x_inn.to(device)).view(n_way, n_support + n_query, -1).detach()\n",
    "    if params.method == \"damsl_v1\" or params.method == \"damsl_v2\" :\n",
    "      final = classifier(output_all)\n",
    "      batchnorm = model.batchnorm\n",
    "      final = torch.transpose(batchnorm(torch.transpose(final, 1,2)),1,2).contiguous()\n",
    "      z = model.fc2(final.view(-1, *final.size()[2:]))\n",
    "      z = z.view(model.n_way, -1, z.size(1))\n",
    "\n",
    "      print(\"hello\")\n",
    "    elif params.method == \"damsl_v2_gnn\":\n",
    "      z = model.fc2(output_all.view(-1, *output_all.size()[2:]))\n",
    "      z = z.view(model.n_way, -1, z.size(1))\n",
    "    elif params.method == \"damsl_v2_proto\":\n",
    "      final = classifier(output_all)\n",
    "      final = torch.transpose(model.batchnorm(torch.transpose(final, 1,2)),1,2).contiguous()\n",
    "      #z = model.fc_deep(final.view(-1, *final.size()[2:])) ## use fc deep for deep embedding network\n",
    "      #z = z.view(model.n_way, -1, z.size(1))\n",
    "\n",
    "    output_all_l = pretrained_model(x_b_i.to(device)).detach()\n",
    "    final_l = classifier(output_all_l)\n",
    "    final_l = torch.nn.functional.softmax(final_l, dim = 1).detach()\n",
    "\n",
    "    output_all_l_2 = pretrained_model(x_a_i_original.to(device)).detach()\n",
    "    final_l_2 = classifier(output_all_l_2)\n",
    "    final_l_2 = torch.nn.functional.softmax(final_l_2, dim = 1).detach()\n",
    "   \n",
    "    \n",
    "\n",
    "    if \"sbmtl\" or \"damsl\" in params.method:\n",
    "        #### copy baseline feature and instantiate classifer\n",
    "        baseline_feat = copy.deepcopy(model.feature_baseline)\n",
    "        classifier_baseline = Classifier(model.feature_baseline.final_feat_dim, model.n_way) ##instantiate classifier\n",
    "        classifier_baseline.to(device)\n",
    "    \n",
    "        ### freeze layers of baseline feat\n",
    "        names_b = []\n",
    "        for name, param in baseline_feat.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                #print(name)\n",
    "                names.append(name)\n",
    "        \n",
    "        names_sub_b = names_b[:-9] ### last Resnet block can adapt\n",
    "\n",
    "        for name, param in baseline_feat.named_parameters():\n",
    "            if name in names_sub_b:\n",
    "                param.requires_grad = False   \n",
    "\n",
    "        delta_opt_b = torch.optim.Adam(filter(lambda p: p.requires_grad, baseline_feat.parameters()), lr = 0.01)\n",
    "        classifier_opt_b = torch.optim.Adam(classifier_baseline.parameters(), lr = 0.01)\n",
    "\n",
    "        for epoch in range(total_epoch):\n",
    "            rand_id = np.random.permutation(support_size * lengt)\n",
    "\n",
    "            for j in range(0, support_size * lengt, batch_size):\n",
    "                classifier_opt_b.zero_grad()\n",
    "                \n",
    "                delta_opt_b.zero_grad()\n",
    "\n",
    "                #####################################\n",
    "                selected_id = torch.from_numpy( rand_id[j: min(j+batch_size, support_size * lengt)]).to(device)\n",
    "                z_batch = x_a_i[selected_id].to(device)\n",
    "                y_batch = y_a_i[selected_id] \n",
    "                #####################################\n",
    "\n",
    "                output = baseline_feat(z_batch)\n",
    "                score  = classifier_baseline(output)\n",
    "                loss_b = loss_fn(score, y_batch)\n",
    "                #grad = torch.autograd.grad(set_loss, fast_parameters, create_graph=True)\n",
    "\n",
    "                #####################################\n",
    "                loss_b.backward() ### think about how to compute gradients and achieve a good initialization\n",
    "\n",
    "                classifier_opt_b.step()\n",
    "                delta_opt_b.step()\n",
    "        \n",
    "        #output_support_b = baseline_feat(x_a_i_original.to(device)).view(n_way, n_support, -1)\n",
    "        #output_query_b = baseline_feat(x_b_i.to(device)).view(n_way,n_query,-1)\n",
    "\n",
    "      \n",
    "\n",
    "        output_all_b = baseline_feat(x_inn.to(device)).view(n_way, n_support + n_query, -1).detach()\n",
    "        if params.method == \"damsl_v1\" or params.method == \"damsl_v2\" :\n",
    "          final_b = classifier_baseline(output_all_b).detach() ##initial baseline scores\n",
    "          final_b = torch.transpose(model.batchnorm2(torch.transpose(final_b, 1,2)),1,2).contiguous()\n",
    "          z_b = model.fc2(final_b.view(-1, *final_b.size()[2:]))\n",
    "          z_b = z_b.view(model.n_way, -1, z_b.size(1))\n",
    "        elif params.method == \"damsl_v2_gnn\":\n",
    "          z_b = model.fc2(output_all_b.view(-1, *output_all_b.size()[2:]))\n",
    "          z_b = z_b.view(n_way, -1, z_b.size(1))\n",
    "        elif params.method == \"damsl_v2_proto\":\n",
    "          final_b = classifier_baseline(output_all_b).detach()\n",
    "          final_b = torch.transpose(model.batchnorm2(torch.transpose(final_b, 1,2)),1,2).contiguous()\n",
    "          #z_b = model.fc_deep(final_b.view(-1, *final_b.size()[2:]))\n",
    "          #z_b = z_b.view(n_way, -1, z_b.size(1))\n",
    "\n",
    "          #z = torch.cat([z, z_b], dim = 2)\n",
    "\n",
    "          final = torch.cat([final, final_b], dim = 2)\n",
    "          z = model.fc_deep(final.view(-1, *final.size()[2:])) ## use fc deep for deep embedding network\n",
    "          z = z.view(n_way, -1, z.size(1))\n",
    "  \n",
    "          z_support = z[:,:model.n_support,:].contiguous()\n",
    "          z_query = z[:,model.n_support:,:].contiguous()\n",
    "          \n",
    "          z_proto     = z_support.view(model.n_way, model.n_support, -1 ).mean(1) #the shape of z is [n_data, n_dim]\n",
    "          z_query     = z_query.contiguous().view(model.n_way* model.n_query, -1 )\n",
    "\n",
    "          dists = euclidean_dist(z_query, z_proto)\n",
    "          scores = -dists\n",
    "          return scores ## early return\n",
    "\n",
    "        \n",
    "        #final = torch.cat([final, final_b], dim = 2)\n",
    "        \n",
    "        \n",
    "        output_all_b_l = baseline_feat(x_b_i.to(device)).detach()\n",
    "        final_b_l = classifier_baseline(output_all_b_l).detach() ##initial baseline scores\n",
    "        final_b_l = torch.nn.functional.softmax(final_b_l, dim = 1).detach()\n",
    "\n",
    "        \n",
    "        output_all_b_l_2 = baseline_feat(x_a_i_original.to(device)).detach()\n",
    "        final_b_l_2 = classifier_baseline(output_all_b_l_2).detach() ##initial baseline scores\n",
    "        final_b_l_2 = torch.nn.functional.softmax(final_b_l_2, dim = 1).detach()\n",
    "        \n",
    "  \n",
    "        z = torch.cat([z, z_b], dim = 2)\n",
    "        #\n",
    "        #z = model.fc_new(final.view(-1, *final.size()[2:]))\n",
    "        #z = z.view(model.n_way, -1, z.size(1))\n",
    "    else:\n",
    "        z = model.fc2(final.view(-1, *final.size()[2:]))\n",
    "        z = z.view(model.n_way, -1, z.size(1))\n",
    "        #z = torch.cat([z, z_b], dim = 2) ##concatenate\n",
    "\n",
    "    z_stack = [torch.cat([z[:, :model.n_support], z[:, model.n_support + i:model.n_support + i + 1]], dim=1).view(1, -1, z.size(2)) for i in range(n_query)]\n",
    "\n",
    "    score = model.forward_gnn(z_stack)\n",
    "    score = torch.nn.functional.softmax(score, dim = 1).detach()\n",
    "\n",
    "    return score, final_l + final_b_l, final_l_2 + final_b_l_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "##################################################################\n",
    "image_size = 224\n",
    "iter_num = 3\n",
    "n_way  = 5\n",
    "pretrained_dataset = \"miniImageNet\"\n",
    "ds = False\n",
    "\n",
    "n_way = 5\n",
    "n_query = 15\n",
    "\n",
    "few_shot_params = dict(n_way = 5 , n_support = 5) \n",
    "\n",
    "datamgr             =  EuroSAT_few_shot.SetDataManager2(image_size, n_eposide = iter_num, n_query = 15, **few_shot_params)\n",
    "novel_loader        = datamgr.get_data_loader(num_aug = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (elem) in enumerate(novel_loader):\n",
    "      leng = len(elem)\n",
    "      \n",
    "      assert(torch.all(torch.eq(elem[0][0] , elem[1][0])) )\n",
    "      _, y = elem[0]\n",
    "      \n",
    "      liz_x = [x for (x,y) in elem]\n",
    "\n",
    "      x = liz_x[0]\n",
    "\n",
    "      print(x.shape)\n",
    "      break\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[0][0].shape)\n",
    "\n",
    "print(x[0][0])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def renormal(a):   \n",
    "    x_new = (a - a.min())\n",
    "    x_new = x_new / x_new.max() \n",
    "    return x_new\n",
    "\n",
    "plt.imshow(  renormal(x[1][0]).permute(1, 2, 0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = liz_x[7]\n",
    "\n",
    "plt.imshow(  renormal(x2[1][0]).permute(1, 2, 0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model           = damsl_v2.GnnNet( model_dict[\"ResNet10\"], **few_shot_params )\n",
    "checkpoint_dir = \"logs_final_train/checkpoints/miniImageNet/ResNet10_damsl_v2_aug_5way_5shot\"\n",
    "modelfile   = get_assigned_file(checkpoint_dir,600)\n",
    "import json\n",
    "class Bunch(object):\n",
    "  def __init__(self, adict):\n",
    "    self.__dict__.update(adict)\n",
    "\n",
    "with open('commandline_args.txt', 'r') as f:\n",
    "   params = Bunch(json.load(f))\n",
    "\n",
    "params.method = \"damsl_v2\"\n",
    "params.checkpoint_dir = checkpoint_dir\n",
    "\n",
    "\n",
    "if modelfile is not None:\n",
    "    tmp = torch.load(modelfile)\n",
    "    state = tmp['state']\n",
    "    state_keys = list(state.keys())\n",
    "    for _, key in enumerate(state_keys):\n",
    "        if \"feature2.\" in key:\n",
    "            state.pop(key)\n",
    "        if \"feature3.\" in key:\n",
    "            state.pop(key)\n",
    "        if \"classifier2.\" in key:\n",
    "            classifier_found = True\n",
    "            state.pop(key)\n",
    "        if \"classifier3.\" in key:\n",
    "            classifier_found = True\n",
    "            state.pop(key)\n",
    "    model.classifier = Classifier(model.feat_dim, n_way)\n",
    "    model.batchnorm = nn.BatchNorm1d(5, track_running_stats=False)\n",
    "    \n",
    "    model.instantiate_baseline(params)\n",
    "    model.load_state_dict(state)\n",
    "    model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (elem) in enumerate(novel_loader):\n",
    "      leng = len(elem)\n",
    "      \n",
    "      assert(torch.all(torch.eq(elem[0][0] , elem[1][0])) )\n",
    "      _, y = elem[0]\n",
    "      \n",
    "      liz_x = [x for (x,y) in elem]\n",
    "\n",
    "      scores, linear_scores, linear_scores_2 = finetune_classify(liz_x,y, model, state, ds = ds, save_it = 600, n_query = 15, pretrained_dataset=pretrained_dataset, freeze_backbone=False, **few_shot_params)\n",
    "\n",
    "      x = liz_x[0]\n",
    "\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### print out some stuff\n",
    "print(scores.shape)\n",
    "print(linear_scores.shape)\n",
    "\n",
    "#print(scores2.shape)\n",
    "#print(linear_scores_2.shape)\n",
    "##scores2 = scores2.cpu()\n",
    "\n",
    "#scores2 = scores2.reshape(5,15,5)[:,:5,:].reshape(25,5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.argmax(scores, dim = 1))\n",
    "print(torch.argmax(linear_scores, dim = 1))\n",
    "\n",
    "\n",
    "def acc(sco):\n",
    "    y_query = np.repeat(range(n_way ), n_query )\n",
    "\n",
    "    topk_scores, topk_labels = sco.data.topk(1, 1, True, True)\n",
    "    topk_ind = topk_labels.cpu().numpy()\n",
    "\n",
    "    top1_correct = np.sum(topk_ind[:,0] == y_query)\n",
    "    \n",
    "    \n",
    "    correct_this, count_this = float(top1_correct), len(y_query)\n",
    "\n",
    "\n",
    "    return correct_this/ count_this * 100, topk_ind[:,0] == y_query\n",
    "\n",
    "acc_scores, sc_q = acc(scores)\n",
    "scc_linear_scores, lc_q = acc(linear_scores)\n",
    "\n",
    "\n",
    "corrected = [i for i,(x,y) in enumerate(zip(sc_q,lc_q)) if x and not y]\n",
    "\n",
    "made_wrong = [i for i, (x,y) in enumerate(zip(sc_q,lc_q)) if not x and y]\n",
    "\n",
    "always_wrong = [i for i, (x,y) in enumerate(zip(sc_q,lc_q)) if not x and not y]\n",
    "\n",
    "\n",
    "print(corrected)\n",
    "print(made_wrong)\n",
    "print(always_wrong)\n",
    "set_corr = set(corrected)\n",
    "corrected_list = [1 if i in set_corr else 0 for i in range(n_query*n_way)]  \n",
    "print(corrected_list)\n",
    "\n",
    "ls_corrected = np.asarray([s for s,boo in zip(linear_scores.cpu().numpy(), corrected_list) if boo == 1])\n",
    "print(ls_corrected)\n",
    "gt_lab = [s for boo,s in zip(corrected_list,np.repeat(range(n_way ), n_query )) if boo == 1]\n",
    "\n",
    "print(gt_lab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "scores_np = scores.cpu().numpy()\n",
    "\n",
    "#scores2_np = scores2.cpu().numpy()\n",
    "\n",
    "linear_scores_np = ls_corrected\n",
    "linear_scores2_np = linear_scores_2.cpu().numpy()\n",
    "\n",
    "lin_sc = linear_scores_np\n",
    "sc = scores_np\n",
    "lin_sc = np.concatenate((linear_scores_np, linear_scores2_np))\n",
    "\n",
    "#sc = np.concatenate((scores_np, scores2_np))\n",
    "\n",
    "ls_embedded =  TSNE(n_components=2).fit_transform(linear_scores2_np)\n",
    "\n",
    "sc_embedded = TSNE(n_components=2).fit_transform(sc)\n",
    "\n",
    "print(ls_embedded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_subset = pd.DataFrame({'tsne-2d-one':ls_embedded[:,0], 'tsne-2d-two': ls_embedded[:,1], \"y\" : list(np.repeat(range(n_way ), 5 ))})\n",
    "\n",
    "#df_subset = pd.DataFrame({'tsne-2d-one':ls_embedded[:,0], 'tsne-2d-two': ls_embedded[:,1], \"y\" : list(np.repeat(range(n_way ), n_query )), \"style\": corrected_list})\n",
    "\n",
    "#df_subset = pd.DataFrame({'tsne-2d-one':ls_embedded[:,0], 'tsne-2d-two': ls_embedded[:,1], \"y\" :  gt_lab + list(np.repeat(range(n_way ), 5 )), \"style\": [0] * len(ls_corrected) + [1] * 25  })\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 5),\n",
    "    #style = \"style\",\n",
    "    data=df_subset,\n",
    "    legend=\"full\",\n",
    "    alpha=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_subset = pd.DataFrame({'tsne-2d-one':sc_embedded[:,0], 'tsne-2d-two': ls_embedded[:,1], \"y\" : list(np.repeat(range(n_way), n_query )),  \"style\": corrected_list})\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 5),\n",
    "    style = \"style\",\n",
    "    data=df_subset,\n",
    "    legend=\"full\",\n",
    "    alpha=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_embedded =  TSNE(n_components=2).fit_transform(linear_scores_np)\n",
    "\n",
    "sc_embedded = TSNE(n_components=2).fit_transform(scores_np)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_subset = pd.DataFrame({'tsne-2d-one':ls_embedded[:,0], 'tsne-2d-two': ls_embedded[:,1], \"y\" : list(np.repeat(range(n_way ), n_query )) , \"style\": [0] * 75 })\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 5),\n",
    "    data=df_subset,\n",
    "    legend=\"full\",\n",
    "    alpha=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = pd.DataFrame({'tsne-2d-one':sc_embedded[:,0], 'tsne-2d-two': sc_embedded[:,1], \"y\" : list(np.repeat(range(n_way ), n_query )) , \"style\": [0] * 75 })\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 5),\n",
    "    data=df_subset,\n",
    "    legend=\"full\",\n",
    "    alpha=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}